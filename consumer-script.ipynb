{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472d5985-f91a-4e7f-9510-4f5d236f60d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from kafka import KafkaConsumer\n",
    "from pyspark.sql import SparkSession\n",
    "from urllib.request import urlopen\n",
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import sum, col, month, year, dayofweek, dayofmonth, hour, unix_timestamp, median, mode, lit, when, from_json, expr\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, DoubleType, LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c576f2dc-f068-4772-852d-a3777a26338d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Stream Processing').getOrCreate()\n",
    "\n",
    "# Setting AWS Access Credentials \n",
    "spark.conf.set(\"fs.s3a.access.key\", str(os.environ['AWS_ACCESS_KEY']))\n",
    "spark.conf.set(\"fs.s3a.secret.key\", str(os.environ['AWS_SECRET_ACCESS_KEY']))\n",
    "spark.conf.set(\"fs.s3a.endpoint\", \"s3.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "245a1e51-00ab-4277-a2ed-57251e170532",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "model = GBTRegressionModel.load('s3://data228/trained-models/gbt_model/')\n",
    "\n",
    "# Incoming data stream schema\n",
    "schema = StructType([\n",
    "    StructField(\"VendorID\", LongType(), nullable=True),\n",
    "    StructField(\"tpep_pickup_datetime\", StringType(), nullable=True),\n",
    "    StructField(\"tpep_dropoff_datetime\", StringType(), nullable=True),\n",
    "    StructField(\"passenger_count\", IntegerType(), nullable=True),\n",
    "    StructField(\"trip_distance\", DoubleType(), nullable=True),\n",
    "    StructField(\"PULocationID\", LongType(), nullable=True),\n",
    "    StructField(\"DOLocationID\", LongType(), nullable=True),\n",
    "    StructField(\"RateCodeID\", DoubleType(), nullable=True),\n",
    "    StructField(\"Store_and_fwd_flag\", StringType(), nullable=True),\n",
    "    StructField(\"payment_type\", LongType(), nullable=True),\n",
    "    StructField(\"Fare_amount\", DoubleType(), nullable=True),\n",
    "    StructField(\"Extra\", DoubleType(), nullable=True),\n",
    "    StructField(\"MTA_tax\", DoubleType(), nullable=True),\n",
    "    StructField(\"Improvement_surcharge\", DoubleType(), nullable=True),\n",
    "    StructField(\"tip_amount\", DoubleType(), nullable=True),\n",
    "    StructField(\"Tolls_amount\", DoubleType(), nullable=True),\n",
    "    StructField(\"total_amount\", DoubleType(), nullable=True),\n",
    "    StructField(\"Congestion_Surcharge\", DoubleType(), nullable=True),\n",
    "    StructField(\"Airport_fee\", DoubleType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccaebc4d-90e3-4d7e-b624-1b93a2228026",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def enrichWithWeatherData(df):\n",
    "    df = df \\\n",
    "    .withColumn(\"trip_duration\", (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\"))) \\\n",
    "    .withColumn('year', F.year(\"tpep_pickup_datetime\")) \\\n",
    "    .withColumn('month', F.month(\"tpep_pickup_datetime\")) \\\n",
    "    .withColumn('weekend', F.when((F.dayofweek(\"tpep_pickup_datetime\") == 1) | (F.dayofweek(\"tpep_pickup_datetime\") == 7), lit(1)).otherwise(lit(0))) \\\n",
    "    .withColumn('date', F.dayofmonth(\"tpep_pickup_datetime\")) \\\n",
    "    .withColumn('hour', F.hour(\"tpep_pickup_datetime\")) \n",
    "\n",
    "    # Extract year, month, date, and hour from the DataFrame row\n",
    "    year, month, date, hour = df.select('year', 'month', 'date', 'hour').collect()[0]\n",
    "\n",
    "    # Fetch weather data using the API\n",
    "    ResultBytes = urlopen(f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/new%20york%2C%20ny/{year}-{month}-{date}/{year}-{month}-{date}?unitGroup=us&include=hours&key={API_KEY}&contentType=json\")\n",
    "\n",
    "    # Parse the results as JSON\n",
    "    jsonData = json.load(ResultBytes)\n",
    "    weather = jsonData['days'][0]['hours'][hour]\n",
    "\n",
    "    # Add weather data to the DataFrame row\n",
    "    df = df \\\n",
    "        .withColumn('temp', lit(weather['temp'])) \\\n",
    "        .withColumn('dew', lit(weather['dew'])) \\\n",
    "        .withColumn('humidity', lit(weather['humidity'])) \\\n",
    "        .withColumn('windspeed', lit(weather['windspeed'])) \\\n",
    "        .withColumn('visibility', lit(weather['visibility']))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d874d538-dc30-496e-ad97-d284d751931f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Price: 12.8 | Predicted Price: 13.52\n",
      "Actual Price: 63.1 | Predicted Price: 49.3\n",
      "Actual Price: 61.85 | Predicted Price: 50.97\n",
      "Actual Price: 44.050000000000004 | Predicted Price: 48.74\n",
      "Actual Price: 29.299999999999997 | Predicted Price: 33.13\n",
      "Actual Price: 12.3 | Predicted Price: 12.08\n",
      "Actual Price: 16.8 | Predicted Price: 17.62\n",
      "Actual Price: 11.8 | Predicted Price: 13.29\n",
      "Actual Price: 9.3 | Predicted Price: 10.86\n",
      "Actual Price: 9.8 | Predicted Price: 10.4\n",
      "Actual Price: 12.3 | Predicted Price: 13.5\n",
      "Actual Price: 60.599999999999994 | Predicted Price: 62.77\n",
      "Actual Price: 34.55 | Predicted Price: 39.27\n",
      "Actual Price: 41.85 | Predicted Price: 38.32\n",
      "Actual Price: 56.55 | Predicted Price: 58.86\n",
      "Actual Price: 63.099999999999994 | Predicted Price: 60.92\n",
      "Actual Price: 11.3 | Predicted Price: 10.95\n",
      "Actual Price: 60.6 | Predicted Price: 58.85\n",
      "Actual Price: 10.3 | Predicted Price: 10.5\n",
      "Actual Price: 8.3 | Predicted Price: 7.96\n",
      "Actual Price: 9.3 | Predicted Price: 10.14\n",
      "Actual Price: 8.8 | Predicted Price: 7.99\n",
      "Actual Price: 16.299999999999997 | Predicted Price: 16.31\n",
      "Actual Price: 17.8 | Predicted Price: 17.79\n",
      "Actual Price: 10.8 | Predicted Price: 10.85\n",
      "Actual Price: 32.05 | Predicted Price: 34.81\n",
      "Actual Price: 33.55 | Predicted Price: 35.34\n",
      "Actual Price: 31.55 | Predicted Price: 35.01\n",
      "Actual Price: 14.8 | Predicted Price: 15.62\n",
      "Actual Price: 10.299999999999999 | Predicted Price: 10.74\n",
      "Actual Price: 14.8 | Predicted Price: 14.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOPIC = \"taxi-trips-topic\"\n",
    "BROKER_IP = '34.209.9.254:9092'\n",
    "API_KEY = \"ZW87PLPVYKDAEG8DR9ZLMS8RW\"\n",
    "\n",
    "consumer = KafkaConsumer(TOPIC, bootstrap_servers=[BROKER_IP])\n",
    "\n",
    "for message in consumer:\n",
    "    msg_value = json.loads(message.value.decode('utf-8'))\n",
    "    msg_value['passenger_count'] = int(msg_value['passenger_count'])\n",
    "    print(f\"Actual Price: {msg_value['total_amount'] - msg_value['tip_amount']}\", end=\" | \")\n",
    "    df = spark.createDataFrame([msg_value], schema = schema)\n",
    "    df = enrichWithWeatherData(df)\n",
    "    assembler = VectorAssembler(\n",
    "    inputCols=['year', 'month', 'date', 'hour', 'passenger_count', 'trip_distance', 'trip_duration', 'PULocationID', 'DOLocationID', 'weekend', 'temp', 'dew', 'humidity', 'windspeed', 'visibility'],\n",
    "    outputCol='features')\n",
    "\n",
    "    df = assembler.transform(df)\n",
    "    df = model.transform(df)\n",
    "    print(f\"Predicted Price: {round(df.select('prediction').collect()[0]['prediction'], 2)}\")\n",
    "\n",
    "    df.coalesce(1).write.parquet(\"s3://data228/stream-data-archive/\", mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d625217-5327-4f86-a40f-f337a16a1d50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f6ab436-25ab-4b38-9703-df79115995b5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "consumer-script",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
